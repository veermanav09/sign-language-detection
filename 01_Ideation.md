# Ideation

Sign language is a crucial communication medium for the hearing- and speech-impaired community. However, interaction with non-signers remains a major challenge, leading to social and professional barriers.

The idea behind **SignSpeak** is to bridge this communication gap by building an **autonomous sign language to speech system**. By leveraging **3D hand pose estimation** and machine learning, the system aims to recognize hand gestures accurately and convert them into real-time spoken language.

Unlike traditional 2D approaches, 3D hand pose estimation captures depth, finger orientation, and joint movement, making the system more robust to lighting conditions, hand rotations, and complex gestures.
